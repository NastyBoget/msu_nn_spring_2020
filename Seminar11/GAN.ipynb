{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating config object (argparse workaround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.mnist_path = None\n",
    "config.batch_size = 16\n",
    "config.num_workers = 3\n",
    "config.num_epochs = 10\n",
    "config.noise_size = 50\n",
    "config.print_freq = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torchvision.datasets.FashionMNIST(\"fashion_mnist\", train=True, transform=torchvision.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for image, cat in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential( \n",
    "            nn.Linear(config.noise_size, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 28*28),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(50, 1), \n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create optimizers and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim_G = optim.Adam(params=generator.parameters(), lr=0.0001)\n",
    "optim_D = optim.Adam(params=discriminator.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Variable(torch.FloatTensor(config.batch_size, 28*28))\n",
    "noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size))\n",
    "fixed_noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size).normal_(0, 1))\n",
    "label = Variable(torch.FloatTensor(config.batch_size))\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "1) Посмотрите на реализацию GAN. Постройте интерполяцию между какими-нибудь двумя сгенерированными картинками. (Опционально)Добавьте свертки в генератор и дискриминатор, как в статье про DCGAN.\n",
    "\n",
    "2) Поменяйте ее, чтобы получился LSGAN https://arxiv.org/pdf/1611.04076v2.pdf\n",
    "\n",
    "3) Добавьте к обучению GAN условие на метку, продемонстрируйте условную генерацию. https://arxiv.org/pdf/1411.1784.pdf\n",
    "\n",
    "4) Напишите отчет что попробовали, какие результаты получили, как вам кажется надо обучать GAN, чтобы добиться сходимости?\n",
    "\n",
    "В каждом пункте постройте графики функций потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ERRD_x = np.zeros(config.num_epochs)\n",
    "ERRD_z = np.zeros(config.num_epochs)\n",
    "ERRG = np.zeros(config.num_epochs)\n",
    "N = len(dataloader)\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    for iteration, (images, cat) in enumerate(dataloader):\n",
    "        ####### \n",
    "        # Discriminator stage: maximize log(D(x)) + log(1 - D(G(z))) \n",
    "        #######\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        label.data.fill_(real_label)\n",
    "        input_data = images.view(images.shape[0], -1)\n",
    "        output = discriminator(input_data)\n",
    "        errD_x = criterion(output, label)\n",
    "        ERRD_x[epoch] += errD_x.item()\n",
    "        errD_x.backward()\n",
    "        \n",
    "        # fake \n",
    "        noise.data.normal_(0, 1)\n",
    "        fake = generator(noise)\n",
    "        label.data.fill_(fake_label)\n",
    "        output = discriminator(fake.detach())\n",
    "        errD_z = criterion(output, label)\n",
    "        ERRD_z[epoch] += errD_z.item()\n",
    "        errD_z.backward()\n",
    "        \n",
    "        optim_D.step()\n",
    "        \n",
    "        ####### \n",
    "        # Generator stage: maximize log(D(G(x))\n",
    "        #######\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = discriminator(fake)\n",
    "        errG = criterion(output, label)\n",
    "        ERRG[epoch] += errG.item()\n",
    "        errG.backward()\n",
    "        \n",
    "        optim_G.step()\n",
    "        \n",
    "        if (iteration+1) % config.print_freq == 0:\n",
    "            print('Epoch:{} Iter: {} errD_x: {:.2f} errD_z: {:.2f} errG: {:.2f}'.format(epoch+1,\n",
    "                                                                                            iteration+1, \n",
    "                                                                                            errD_x.item(),\n",
    "                                                                                            errD_z.item(), \n",
    "                                                                                            errG.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise.data.normal_(0, 1)\n",
    "fake = generator(noise)\n",
    "\n",
    "plt.figure(figsize=(6, 7))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(fake[i].detach().numpy().reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
